{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, KFold, StratifiedKFold,\\\n",
    "GroupKFold, cross_validate, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표본추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단순랜덤추출법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length  sepal width  petal length  petal width  target\n",
      "0           5.1          3.5           1.4          0.2     0.0\n",
      "1           4.9          3.0           1.4          0.2     0.0\n",
      "2           4.7          3.2           1.3          0.2     0.0\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "iris_cols = list(data['feature_names']) + ['target']\n",
    "iris = pd.DataFrame(np.c_[data['data'], data['target']], columns=\n",
    "                    [col.replace(' (cm)', '') for col in iris_cols])\n",
    "print(iris.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 1, 2, 4]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = [1,2,3,4,5,'a','b','c']\n",
    "random.sample(data_list, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', 'c', '3', '1'], dtype='<U11')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 넘파이 라이브러리\n",
    "np.random.choice(data_list, 4, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~10 사이의 정수 중 3개의 난수 생성:  [9 2 5]\n",
      "0~1 사이의 실수를 2*2 배열로 생성:\n",
      " [[0.57980441 0.22903363]\n",
      " [0.3809708  0.29916238]]\n"
     ]
    }
   ],
   "source": [
    "# 특정 범위 내의 정수/실수의 난수 생성\n",
    "print('0~10 사이의 정수 중 3개의 난수 생성: ', np.random.randint(0, 10, 3))\n",
    "print('0~1 사이의 실수를 2*2 배열로 생성:\\n', np.random.rand(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal length  sepal width  petal length  petal width  target\n",
      "6            4.6          3.4           1.4          0.3     0.0\n",
      "54           6.5          2.8           4.6          1.5     1.0\n",
      "9            4.9          3.1           1.5          0.1     0.0\n"
     ]
    }
   ],
   "source": [
    "print(iris.sample(n=3, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width  target\n",
      "42            4.4          3.2           1.3          0.2     0.0\n",
      "72            6.3          2.5           4.9          1.5     1.0\n",
      "106           4.9          2.5           4.5          1.7     2.0\n",
      "35            5.0          3.2           1.2          0.2     0.0\n"
     ]
    }
   ],
   "source": [
    "# frac 파라미터로 전체 데이터의 3%를 랜덤으로 추출할 수 있음.\n",
    "print(iris.sample(frac=0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width  target\n",
      "134           6.1          2.6           5.6          1.4     2.0\n",
      "120           6.9          3.2           5.7          2.3     2.0\n",
      "63            6.1          2.9           4.7          1.4     1.0\n",
      "17            5.1          3.5           1.4          0.3     0.0\n"
     ]
    }
   ],
   "source": [
    "print(iris.sample(frac=0.03, weights='sepal length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal width  sepal length  petal length\n",
      "0          3.5           5.1           1.4\n",
      "1          3.0           4.9           1.4\n",
      "2          3.2           4.7           1.3\n"
     ]
    }
   ],
   "source": [
    "print(iris.sample(3, axis=1).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 계통추출법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width  target\n",
      "17            5.1          3.5           1.4          0.3     0.0\n",
      "35            5.0          3.2           1.2          0.2     0.0\n",
      "53            5.5          2.3           4.0          1.3     1.0\n",
      "71            6.1          2.8           4.0          1.3     1.0\n",
      "89            5.5          2.5           4.0          1.3     1.0\n",
      "107           7.3          2.9           6.3          1.8     2.0\n",
      "125           7.2          3.2           6.0          1.8     2.0\n",
      "143           6.8          3.2           5.9          2.3     2.0\n"
     ]
    }
   ],
   "source": [
    "def sys_sampling(data, n) : \n",
    "    N = len(data)\n",
    "    K = N//n\n",
    "    index = data[:K].sample(1).index  # 첫 구간에서 임의로 선택한 샘플 1개의 인덱스\n",
    "    # index개씩 띄어서 각 구간에서 하나씩 샘플 추출\n",
    "    sys_df = pd.DataFrame()\n",
    "    while len(sys_df) < n : \n",
    "        # sys_df = sys_df.append(data.loc[index,:])\n",
    "        sys_df = pd.concat([sys_df, data.loc[index,:]])\n",
    "        index += K\n",
    "    return sys_df\n",
    "\n",
    "print(sys_sampling(iris, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 집락 추출법/층화추출법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_random_sampling(data, stratum, sampling_no, proportion=True) :\n",
    "    if proportion == True : # 비례층화추출법: 원본 데이터 개수의 비율대로 추출\n",
    "        levels = data[stratum].unique()\n",
    "        total = data[stratum].value_counts().sum()\n",
    "        prop_val = data[stratum].value_counts()/total\n",
    "        no = prop_val * sampling_no\n",
    "        result = pd.DataFrame()\n",
    "        for level in levels : \n",
    "            temp_df = data[data[stratum]==level].sample(int(no[level]))\n",
    "            result = pd.concat([result, temp_df])\n",
    "\n",
    "    else :  # 불비례층화추출법: 임의로 정한 특정 비율대로 샘플링\n",
    "        levels = list(proportion.keys())\n",
    "        prop_val = np.array(list(proportion.values()))\n",
    "        total = sum(prop_val)\n",
    "        no = prop_val * sampling_no\n",
    "        if total != 1 : \n",
    "            raise Exception('proportion sum is supposed to be 1.')\n",
    "        else : \n",
    "            result = pd.DataFrame()\n",
    "            for level in levels : \n",
    "                temp_df = data[data[stratum]==level].sample(int(no[level]))\n",
    "                result = pd.concat([result, temp_df])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    50\n",
       "1.0    50\n",
       "2.0    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 층별 데이터 개수 확인: 층별로 동일하게 50개씩 관측값을 가지는 데이터\n",
    "iris['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width  target\n",
      "22            4.6          3.6           1.0          0.2     0.0\n",
      "11            4.8          3.4           1.6          0.2     0.0\n",
      "34            4.9          3.1           1.5          0.2     0.0\n",
      "81            5.5          2.4           3.7          1.0     1.0\n",
      "57            4.9          2.4           3.3          1.0     1.0\n",
      "95            5.7          3.0           4.2          1.2     1.0\n",
      "110           6.5          3.2           5.1          2.0     2.0\n",
      "120           6.9          3.2           5.7          2.3     2.0\n",
      "132           6.4          2.8           5.6          2.2     2.0\n"
     ]
    }
   ],
   "source": [
    "# 비례층화추출법으로 9개 샘플링하기: 원본과 동일한 비율로 샘플링하기\n",
    "print(start_random_sampling(iris, 'target', 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width  target\n",
      "26            5.0          3.4           1.6          0.4     0.0\n",
      "17            5.1          3.5           1.4          0.3     0.0\n",
      "80            5.5          2.4           3.8          1.1     1.0\n",
      "84            5.4          3.0           4.5          1.5     1.0\n",
      "85            6.0          3.4           4.5          1.6     1.0\n",
      "81            5.5          2.4           3.7          1.0     1.0\n",
      "93            5.0          2.3           3.3          1.0     1.0\n",
      "148           6.2          3.4           5.4          2.3     2.0\n",
      "147           6.5          3.0           5.2          2.0     2.0\n",
      "133           6.3          2.8           5.1          1.5     2.0\n"
     ]
    }
   ],
   "source": [
    "# 불비례층화추출법으로 10개 샘플링하기: 임의로 정한 비율로 샘플링하기\n",
    "print(start_random_sampling(iris, 'target', 10, proportion={0:0.2, 1:0.5,\n",
    "                                                            2:0.3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반적인 데이터 분할 및 홀드아웃 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train(y_train): 105(105), X_test(y_test): 45(45)\n",
      "X_train의 비율: 0.70, X_test의 비율: 0.30 \n",
      "\n",
      "X_train(y_train): 75(75), X_test(y_test) 75(75)\n",
      "X_train의 비율: 0.50, X_test의 비율: 0.50\n"
     ]
    }
   ],
   "source": [
    "X = iris.drop('target', axis=1)\n",
    "y = iris.filter(['target'])\n",
    "\n",
    "# 일반적 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print('X_train(y_train): %d(%d), X_test(y_test): %d(%d)' % (len(X_train), len(y_train), len(X_test), len(y_test)))\n",
    "print('X_train의 비율: %0.2f, X_test의 비율: %0.2f' % (len(X_train)/len(X), len(X_test)/len(X)), '\\n')\n",
    "\n",
    "# 홀드아웃 방법\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "print('X_train(y_train): %d(%d), X_test(y_test) %d(%d)' % (len(X_train), len(y_train), len(X_test), len(y_test)))\n",
    "print('X_train의 비율: %0.2f, X_test의 비율: %0.2f' % (len(X_train)/len(X), len(X_test)/len(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bootstrap: 랜덤복원추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: Int64Index([17, 24, 9], dtype='int64'), test_index: Int64Index([0, 2, 3], dtype='int64')\n",
      "\tX_train의 비율: 0.70, X_test의 비율: 0.30\n",
      "\ty_train의 타겟 구성: Counter({1.0: 38, 0.0: 34, 2.0: 33})\n",
      "\ty_test의 타겟 구성: Counter({2.0: 17, 0.0: 16, 1.0: 12}) \n",
      "\n",
      "Sample 1 ==> train_index: Int64Index([49, 13, 79], dtype='int64'), test_index: Int64Index([1, 8, 9], dtype='int64')\n",
      "\tX_train의 비율: 0.70, X_test의 비율: 0.30\n",
      "\ty_train의 타겟 구성: Counter({1.0: 38, 2.0: 35, 0.0: 32})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 18, 2.0: 15, 1.0: 12}) \n",
      "\n",
      "Sample 2 ==> train_index: Int64Index([18, 48, 28], dtype='int64'), test_index: Int64Index([1, 2, 8], dtype='int64')\n",
      "\tX_train의 비율: 0.70, X_test의 비율: 0.30\n",
      "\ty_train의 타겟 구성: Counter({0.0: 36, 1.0: 36, 2.0: 33})\n",
      "\ty_test의 타겟 구성: Counter({2.0: 17, 0.0: 14, 1.0: 14}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def Bootstrap(X, y, test_size = 0.3) : \n",
    "    train_size = 1 - test_size\n",
    "    train_X = X.sample(frac=train_size)\n",
    "    sampled_train_id = train_X.index\n",
    "    sampled_test_id = X.drop(train_X.index, axis=0).index\n",
    "    train_y = y.iloc[sampled_train_id,:]\n",
    "    test_X = X.iloc[sampled_test_id,:]\n",
    "    test_y = y.iloc[sampled_test_id,:]\n",
    "    return train_X, test_X, train_y, test_y\n",
    "\n",
    "for i in range(3) : \n",
    "    X_train, X_test, y_train, y_test = Bootstrap(X, y)\n",
    "    print(f'Sample {i} ==> train_index: {X_train.index[:3]}, test_index: {X_test.index[:3]}')\n",
    "    print('\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f' % (len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print('\\ty_train의 타겟 구성:', Counter(y_train['target']))\n",
    "    print('\\ty_test의 타겟 구성:', Counter(y_test['target']), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shuffle Split: 무작위 순열 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [ 19  31 117], test_index: [  3  59 147]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({1.0: 30, 2.0: 24, 0.0: 21})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 29, 2.0: 26, 1.0: 20}) \n",
      "\n",
      "Sample 1 ==> train_index: [45 92  7], test_index: [116  84  12]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({1.0: 26, 2.0: 26, 0.0: 23})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 27, 2.0: 24, 1.0: 24}) \n",
      "\n",
      "Sample 2 ==> train_index: [ 72  49 144], test_index: [107  44 122]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({1.0: 26, 0.0: 25, 2.0: 24})\n",
      "\ty_test의 타겟 구성: Counter({2.0: 26, 0.0: 25, 1.0: 24}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ss = ShuffleSplit(test_size=0.5, train_size=0.5, n_splits=3)\n",
    "for i, (train_index, test_index) in enumerate(ss.split(X)) : \n",
    "    print(f'Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}')\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index,:], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print('\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f' % (len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print('\\ty_train의 타겟 구성:', Counter(y_train['target']))\n",
    "    print('\\ty_test의 타겟 구성:', Counter(y_test['target']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-fold 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [38 39 40], test_index: [0 1 2]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({1.0: 50, 2.0: 50, 0.0: 12})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 38}) \n",
      "\n",
      "Sample 1 ==> train_index: [0 1 2], test_index: [38 39 40]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({2.0: 50, 0.0: 38, 1.0: 24})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 26, 0.0: 12}) \n",
      "\n",
      "Sample 2 ==> train_index: [0 1 2], test_index: [76 77 78]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 50, 2.0: 37, 1.0: 26})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 24, 2.0: 13}) \n",
      "\n",
      "Sample 3 ==> train_index: [0 1 2], test_index: [113 114 115]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 50, 1.0: 50, 2.0: 13})\n",
      "\ty_test의 타겟 구성: Counter({2.0: 37}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle=False)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)) : \n",
    "    print(f'Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}')\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index,:], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print('\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f' % (len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print('\\ty_train의 타겟 구성:', Counter(y_train['target']))\n",
    "    print('\\ty_test의 타겟 구성:', Counter(y_test['target']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stratified K-fold 분할: 불균형 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [13 14 15], test_index: [0 1 2]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({1.0: 38, 0.0: 37, 2.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 13, 2.0: 13, 1.0: 12})\n",
      "Sample 1 ==> train_index: [0 1 2], test_index: [13 14 15]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({1.0: 38, 0.0: 37, 2.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 13, 2.0: 13, 1.0: 12})\n",
      "Sample 2 ==> train_index: [0 1 2], test_index: [26 27 28]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 38, 2.0: 38, 1.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 13, 0.0: 12, 2.0: 12})\n",
      "Sample 3 ==> train_index: [0 1 2], test_index: [38 39 40]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 38, 2.0: 38, 1.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 13, 0.0: 12, 2.0: 12})\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "# 분할 시 y를 고려해야 하기 때문에 split에 y를 입력해 주어야 함.\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)) : \n",
    "    print(f'Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}')\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index,:], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print('\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f' % (len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print('\\ty_train의 타겟 구성:', Counter(y_train['target']))\n",
    "    print('\\ty_test의 타겟 구성:', Counter(y_test['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Group K-fold 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length  sepal width  petal length  petal width  target  group\n",
      "0           5.1          3.5           1.4          0.2     0.0      3\n",
      "1           4.9          3.0           1.4          0.2     0.0      2\n",
      "2           4.7          3.2           1.3          0.2     0.0      3\n"
     ]
    }
   ],
   "source": [
    "# group이 있는 데이터 생성하기\n",
    "# group은 0,1,2,3의 4종류가 있음.\n",
    "iris2 = iris.copy()\n",
    "iris2['group'] = iris2['target'].apply(lambda x: int(np.random.randint(0,4,1)))\n",
    "print(iris2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [1 3 4], test_index: [0 2 7]\n",
      "\tX_train의 비율: 0.69, X_test의 비율: 0.31\n",
      "\ttrain의 타겟 구성: Counter({1.0: 37, 2.0: 36, 0.0: 31})\n",
      "\ttest의 타겟 구성: Counter({0.0: 19, 2.0: 14, 1.0: 13})\n",
      "\ttrain의 그룹 구성: Counter({0: 38, 2: 36, 1: 30})\n",
      "\ttest의 그룹 구성: Counter({3: 46})\n",
      "Sample 1 ==> train_index: [0 1 2], test_index: [4 5 6]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ttrain의 타겟 구성: Counter({1.0: 40, 0.0: 37, 2.0: 35})\n",
      "\ttest의 타겟 구성: Counter({2.0: 15, 0.0: 13, 1.0: 10})\n",
      "\ttrain의 그룹 구성: Counter({3: 46, 2: 36, 1: 30})\n",
      "\ttest의 그룹 구성: Counter({0: 38})\n",
      "Sample 2 ==> train_index: [0 2 4], test_index: [1 3 9]\n",
      "\tX_train의 비율: 0.76, X_test의 비율: 0.24\n",
      "\ttrain의 타겟 구성: Counter({2.0: 41, 0.0: 40, 1.0: 33})\n",
      "\ttest의 타겟 구성: Counter({1.0: 17, 0.0: 10, 2.0: 9})\n",
      "\ttrain의 그룹 구성: Counter({3: 46, 0: 38, 1: 30})\n",
      "\ttest의 그룹 구성: Counter({2: 36})\n",
      "Sample 3 ==> train_index: [0 1 2], test_index: [15 17 19]\n",
      "\tX_train의 비율: 0.80, X_test의 비율: 0.20\n",
      "\ttrain의 타겟 구성: Counter({0.0: 42, 1.0: 40, 2.0: 38})\n",
      "\ttest의 타겟 구성: Counter({2.0: 12, 1.0: 10, 0.0: 8})\n",
      "\ttrain의 그룹 구성: Counter({3: 46, 0: 38, 2: 36})\n",
      "\ttest의 그룹 구성: Counter({1: 30})\n"
     ]
    }
   ],
   "source": [
    "X = iris2.drop(['target', 'group'], axis=1)\n",
    "y = iris2.filter(['target'])\n",
    "group = iris2.filter(['group'])\n",
    "gkf = GroupKFold(n_splits=4)\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X, y, group)) : \n",
    "    print(f'Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}')\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index,:], X.iloc[test_index], \\\n",
    "        y.iloc[train_index], y.iloc[test_index]\n",
    "    print('\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f' % (len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print('\\ttrain의 타겟 구성:', Counter(y_train['target']))\n",
    "    print('\\ttest의 타겟 구성:', Counter(y_test['target']))\n",
    "    print('\\ttrain의 그룹 구성:', Counter(group.iloc[train_index]['group']))\n",
    "    print('\\ttest의 그룹 구성:', Counter(group.iloc[test_index]['group']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분할 샘플들로 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fit_time  score_time  test_score  train_score\n",
      "0  0.072053    0.002004    0.894737     0.955357\n",
      "1  0.007999    0.001001    0.947368     0.964286\n",
      "2  0.008000    0.001001    0.945946     0.955752\n",
      "3  0.007999    0.001001    1.000000     0.938053\n"
     ]
    }
   ],
   "source": [
    "X = iris.drop('target', axis=1)\n",
    "y = iris['target']\n",
    "\n",
    "LOGREG = LogisticRegression(max_iter=300, C=0.1)\n",
    "\n",
    "# 샘플 분할 방법 정의하기\n",
    "SKF = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# 교차 검증 실시하기\n",
    "result = cross_validate(LOGREG, X, y, cv = SKF, return_train_score=True)\n",
    "print(pd.DataFrame(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파라미터 후보들로 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 교차 검증 점수: 0.96\n",
      "최적의 매개변수: {'C': 1, 'solver': 'lbfgs'}\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0       0.011512  4.523396e-03         0.001488        0.000521    0.01   \n",
      "1       0.003503  4.951954e-04         0.000996        0.000004    0.01   \n",
      "2       0.007499  5.006790e-04         0.000500        0.000500     0.1   \n",
      "3       0.001500  4.999638e-04         0.001502        0.000502     0.1   \n",
      "4       0.014081  8.511543e-05         0.001003        0.000002       1   \n",
      "5       0.001007  9.536743e-07         0.001006        0.000000       1   \n",
      "\n",
      "  param_solver                              params  split0_test_score  \\\n",
      "0        lbfgs      {'C': 0.01, 'solver': 'lbfgs'}           0.800000   \n",
      "1    liblinear  {'C': 0.01, 'solver': 'liblinear'}           0.666667   \n",
      "2        lbfgs       {'C': 0.1, 'solver': 'lbfgs'}           0.920000   \n",
      "3    liblinear   {'C': 0.1, 'solver': 'liblinear'}           0.786667   \n",
      "4        lbfgs         {'C': 1, 'solver': 'lbfgs'}           0.960000   \n",
      "5    liblinear     {'C': 1, 'solver': 'liblinear'}           0.946667   \n",
      "\n",
      "   split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0           0.866667         0.833333        0.033333                4  \n",
      "1           0.666667         0.666667        0.000000                6  \n",
      "2           0.973333         0.946667        0.026667                2  \n",
      "3           0.813333         0.800000        0.013333                5  \n",
      "4           0.960000         0.960000        0.000000                1  \n",
      "5           0.946667         0.946667        0.000000                3  \n"
     ]
    }
   ],
   "source": [
    "LOGREG = LogisticRegression(max_iter=300, C=0.1)\n",
    "\n",
    "# 알고리즘의 파라미터 후보군을 정의하기\n",
    "param_grid = {'C':[0.01, 0.1, 1], 'solver':['lbfgs', 'liblinear']}\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=2)\n",
    "\n",
    "grid = GridSearchCV(LOGREG, param_grid, cv=SKF)\n",
    "grid.fit(X,y)\n",
    "\n",
    "print(f'최상의 교차 검증 점수: {grid.best_score_:.2f}')\n",
    "print(f'최적의 매개변수: {grid.best_params_}')\n",
    "print(pd.DataFrame(grid.cv_results_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
